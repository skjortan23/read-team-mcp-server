#!/usr/bin/env python3
"""
Exploit Database Population Tool

This script connects to Metasploit RPC server and populates the MongoDB exploits
collection with detailed information about all available exploits for fast searching.

Run this script once during setup or when you want to refresh the exploit database.
"""

import json
import os
import re
import time
from datetime import datetime
from typing import Dict, List, Optional, Any
import logging
from concurrent.futures import ThreadPoolExecutor, as_completed
import threading

from red_team_mcp import database
from red_team_mcp.metasploit_scanner import get_metasploit_client

logger = logging.getLogger(__name__)

# Thread-local storage for Metasploit clients
thread_local = threading.local()


def get_thread_local_client():
    """Get a thread-local Metasploit client."""
    if not hasattr(thread_local, 'client'):
        thread_local.client = get_metasploit_client()
    return thread_local.client


def extract_cve_references(description: str, references: List[str] = None) -> List[str]:
    """Extract CVE references from description and references."""
    cve_pattern = r'CVE-\d{4}-\d{4,7}'
    cves = set()

    # Extract from description
    if description:
        cves.update(re.findall(cve_pattern, description, re.IGNORECASE))

    # Extract from references if available
    if references:
        for ref in references:
            if isinstance(ref, str):
                cves.update(re.findall(cve_pattern, ref, re.IGNORECASE))

    return sorted(list(cves))


def extract_platform_from_name(exploit_name: str) -> str:
    """Extract platform from exploit name."""
    name_lower = exploit_name.lower()

    if name_lower.startswith('windows/'):
        return 'windows'
    elif name_lower.startswith('linux/'):
        return 'linux'
    elif name_lower.startswith('unix/'):
        return 'unix'
    elif name_lower.startswith('osx/') or name_lower.startswith('macos/'):
        return 'macos'
    elif name_lower.startswith('android/'):
        return 'android'
    elif name_lower.startswith('multi/'):
        return 'multi-platform'
    elif name_lower.startswith('mainframe/'):
        return 'mainframe'
    elif name_lower.startswith('bsd/'):
        return 'bsd'
    elif name_lower.startswith('solaris/'):
        return 'solaris'
    elif name_lower.startswith('aix/'):
        return 'aix'
    elif name_lower.startswith('firefox/'):
        return 'firefox'
    elif name_lower.startswith('browser/'):
        return 'browser'
    else:
        return 'unknown'


def safe_convert_to_serializable(obj):
    """Convert objects to JSON-serializable format, handling all edge cases."""
    try:
        if isinstance(obj, (str, int, float, bool, type(None))):
            return obj
        elif isinstance(obj, (list, tuple)):
            return [safe_convert_to_serializable(item) for item in obj]
        elif isinstance(obj, dict):
            # Convert all keys to strings to avoid MongoDB key restrictions
            result = {}
            for k, v in obj.items():
                try:
                    key_str = str(k)
                    result[key_str] = safe_convert_to_serializable(v)
                except Exception:
                    # If conversion fails, skip this key-value pair
                    continue
            return result
        else:
            # For any other type, convert to string
            return str(obj)
    except Exception:
        # If all else fails, return a safe string representation
        return f"<conversion_error: {type(obj).__name__}>"


def safe_get_attribute(obj, attr_name, default=None):
    """Safely get an attribute from a Metasploit object."""
    try:
        value = getattr(obj, attr_name, default)
        # Convert to basic Python types to avoid Metasploit object issues
        if hasattr(value, '__iter__') and not isinstance(value, (str, bytes)):
            try:
                return list(value)
            except:
                return str(value)
        return value
    except Exception:
        return default


def find_metasploit_path():
    """Find the Metasploit installation path."""
    possible_paths = [
        '/opt/metasploit-framework/embedded/framework',  # Common packaged installation
        '/opt/metasploit-framework',
        '/usr/share/metasploit-framework',
        '/usr/local/share/metasploit-framework',
        '/Applications/Metasploit.app/Contents/Resources/metasploit-framework',  # macOS
        '/home/*/metasploit-framework',
        '/root/metasploit-framework'
    ]

    # Check each possible path
    for path in possible_paths:
        expanded_path = os.path.expanduser(path)
        modules_path = os.path.join(expanded_path, 'modules', 'exploits')
        if os.path.exists(modules_path):
            return expanded_path

    return None


def parse_exploit_module_file(file_path, exploit_name):
    """Parse a Metasploit exploit module file to extract metadata."""
    try:
        with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
            content = f.read()

        info = {
            'name': exploit_name,
            'description': f"Metasploit exploit module: {exploit_name}",
            'author': [],
            'references': [],
            'cve_references': [],
            'disclosure_date': None,
            'rank': 'Unknown',
            'platform': extract_platform_from_name(exploit_name),
            'targets': [],
            'required_options': [],
            'all_options': [],
            'compatible_payloads': [],
            'created_at': datetime.now(),
            'updated_at': datetime.now(),
            'data_source': 'filesystem'
        }

        # Extract CVE references from References section
        cves = []

        # Method 1: Look for CVE references in the References array format
        # e.g., ['CVE', '2017-0144']
        cve_ref_matches = re.findall(r"\[\s*'CVE'\s*,\s*'([^']+)'\s*\]", content)
        for cve_num in cve_ref_matches:
            cves.append(f"CVE-{cve_num}")

        # Method 2: Look for %w(CVE 2008-4250) format
        cve_w_matches = re.findall(r"%w\(\s*CVE\s+([^)]+)\)", content)
        for cve_num in cve_w_matches:
            cves.append(f"CVE-{cve_num}")

        # Method 3: Also search for direct CVE patterns in the entire content
        cve_pattern = r'CVE-\d{4}-\d{4,7}'
        direct_cves = re.findall(cve_pattern, content, re.IGNORECASE)
        cves.extend(direct_cves)

        info['cve_references'] = list(set(cves))  # Remove duplicates

        # Extract description
        desc_match = re.search(r"'Description'\s*=>\s*%q\{([^}]+)\}", content, re.DOTALL)
        if not desc_match:
            desc_match = re.search(r"'Description'\s*=>\s*'([^']+)'", content)
        if not desc_match:
            desc_match = re.search(r"'Description'\s*=>\s*\"([^\"]+)\"", content)
        if desc_match:
            info['description'] = desc_match.group(1).strip()

        # Extract author(s)
        author_matches = re.findall(r"'Author'\s*=>\s*\[(.*?)\]", content, re.DOTALL)
        if author_matches:
            author_text = author_matches[0]
            # Extract individual authors
            authors = re.findall(r"'([^']+)'", author_text)
            info['author'] = ', '.join(authors)
        else:
            # Single author
            author_match = re.search(r"'Author'\s*=>\s*'([^']+)'", content)
            if author_match:
                info['author'] = author_match.group(1)

        # Extract disclosure date
        date_match = re.search(r"'DisclosureDate'\s*=>\s*'([^']+)'", content)
        if date_match:
            info['disclosure_date'] = date_match.group(1)

        # Extract rank
        rank_match = re.search(r"Rank\s*=\s*(\w+)", content)
        if rank_match:
            info['rank'] = rank_match.group(1).replace('Ranking', '')  # Remove 'Ranking' suffix

        # Extract payload constraints/info from the module
        payload_info = []

        # Look for payload space constraints
        space_match = re.search(r"'Space'\s*=>\s*(\d+)", content)
        if space_match:
            payload_info.append(f"Space: {space_match.group(1)} bytes")

        # Look for payload arch constraints - handle multiple formats
        # Format 1: 'Arch' => [ARCH_X64]
        arch_match = re.search(r"'Arch'\s*=>\s*\[(.*?)\]", content, re.DOTALL)
        if arch_match:
            arch_text = arch_match.group(1)
            # Extract ARCH_ constants
            archs = re.findall(r"ARCH_(\w+)", arch_text)
            if archs:
                payload_info.append(f"Arch: {', '.join(archs)}")
        else:
            # Format 2: 'Arch' => 'x86'
            arch_match = re.search(r"'Arch'\s*=>\s*'([^']+)'", content)
            if arch_match:
                payload_info.append(f"Arch: {arch_match.group(1)}")

        # Look for platform constraints
        platform_constraint_match = re.search(r"'Platform'\s*=>\s*'([^']+)'", content)
        if platform_constraint_match:
            payload_info.append(f"Platform: {platform_constraint_match.group(1)}")

        # Look for encoder type constraints
        encoder_match = re.search(r"'EncoderType'\s*=>\s*([^,\n}]+)", content)
        if encoder_match:
            encoder_type = encoder_match.group(1).strip()
            if "Raw" in encoder_type:
                payload_info.append("Encoder: Raw (no encoding)")
            else:
                payload_info.append(f"Encoder: {encoder_type}")

        # Look for BadChars constraints
        badchars_match = re.search(r"'BadChars'\s*=>\s*'([^']*)'", content)
        if badchars_match:
            badchars = badchars_match.group(1)
            if badchars:
                payload_info.append(f"BadChars: {repr(badchars)}")
            else:
                payload_info.append("BadChars: None")

        # Look for DisableNops setting
        if "'DisableNops' => true" in content:
            payload_info.append("NOPs: Disabled")

        # Store payload constraints separately from compatible payloads
        info['payload_constraints'] = payload_info if payload_info else []
        info['compatible_payloads'] = []  # Will be filled by RPC or fallback

        return info

    except Exception as e:
        logger.warning(f"Failed to parse exploit file {file_path}: {e}")
        return None


def try_get_compatible_payloads_via_rpc(client, exploit_name: str) -> List[str]:
    """Try to get actual compatible payload modules via console RPC."""
    try:
        # Use console approach to get compatible payloads
        console_obj = client.consoles.console()
        console_id = console_obj.cid

        # Send commands to get compatible payloads
        console_obj.write(f'use exploit/{exploit_name}\n')
        time.sleep(1)

        console_obj.write('show payloads\n')
        time.sleep(2)  # Give time for command to execute

        # Read output
        output_result = console_obj.read()

        # Clean up console
        console_obj.destroy()

        if isinstance(output_result, dict):
            output_data = output_result.get('data', '')

            # Parse payload names from output
            # Look for lines with payload indices: "   1   payload/windows/..."
            payload_pattern = r'^\s*\d+\s+([a-zA-Z0-9_/]+)\s+'
            payload_matches = re.findall(payload_pattern, output_data, re.MULTILINE)

            if payload_matches:
                # Clean up payload names (remove 'payload/' prefix if present)
                cleaned_payloads = []
                for payload in payload_matches:
                    if payload.startswith('payload/'):
                        cleaned_payloads.append(payload[8:])  # Remove 'payload/' prefix
                    else:
                        cleaned_payloads.append(payload)

                # Return a reasonable subset to avoid huge lists
                return cleaned_payloads[:20]

    except Exception as e:
        logger.debug(f"Console payload retrieval failed for {exploit_name}: {e}")

        # Fallback to platform-based common payloads
        try:
            platform = extract_platform_from_name(exploit_name)
            return get_common_payloads_for_platform(platform)
        except Exception:
            pass

    return []


def get_common_payloads_for_platform(platform: str) -> List[str]:
    """Get common payload modules for a given platform."""
    common_payloads = {
        'windows': [
            'windows/meterpreter/reverse_tcp',
            'windows/shell/reverse_tcp',
            'windows/x64/meterpreter/reverse_tcp',
            'windows/x64/shell/reverse_tcp',
            'windows/meterpreter/bind_tcp',
            'windows/shell/bind_tcp'
        ],
        'linux': [
            'linux/x86/meterpreter/reverse_tcp',
            'linux/x86/shell/reverse_tcp',
            'linux/x64/meterpreter/reverse_tcp',
            'linux/x64/shell/reverse_tcp',
            'linux/x86/shell_reverse_tcp',
            'linux/x64/shell_reverse_tcp'
        ],
        'unix': [
            'cmd/unix/reverse',
            'cmd/unix/bind_netcat',
            'cmd/unix/reverse_netcat',
            'generic/shell_reverse_tcp',
            'generic/shell_bind_tcp'
        ],
        'osx': [
            'osx/x86/shell_reverse_tcp',
            'osx/x64/shell_reverse_tcp',
            'osx/x86/shell_bind_tcp'
        ],
        'android': [
            'android/meterpreter/reverse_tcp',
            'android/shell/reverse_tcp'
        ]
    }

    return common_payloads.get(platform, ['generic/shell_reverse_tcp'])


def get_exploit_detailed_info_via_rpc(exploit_name: str) -> Optional[Dict[str, Any]]:
    """Get detailed information about a specific exploit using pure RPC approach."""
    try:
        client = get_thread_local_client()

        # Load the exploit module via RPC
        exploit_obj = client.modules.use('exploit', exploit_name)
        if not exploit_obj:
            logger.debug(f"Failed to load exploit module via RPC: {exploit_name}")
            return None

        # Extract information from the exploit object
        info = {
            'name': exploit_name,
            'description': safe_get_attribute(exploit_obj, 'description', f"Metasploit exploit module: {exploit_name}"),
            'author': safe_get_attribute(exploit_obj, 'author', 'Unknown'),
            'references': safe_get_attribute(exploit_obj, 'references', []),
            'disclosure_date': safe_get_attribute(exploit_obj, 'disclosure_date'),
            'rank': safe_get_attribute(exploit_obj, 'rank', 'Unknown'),
            'platform': extract_platform_from_name(exploit_name),
            'targets': safe_get_attribute(exploit_obj, 'targets', []),
            'required_options': safe_get_attribute(exploit_obj, 'missing_required', []),
            'all_options': safe_get_attribute(exploit_obj, 'options', []),
            'compatible_payloads': [],
            'cve_references': [],
            'payload_constraints': [],
            'created_at': datetime.now(),
            'updated_at': datetime.now(),
            'data_source': 'rpc'
        }

        # Extract CVE references from description and references
        description = info.get('description', '')
        references = info.get('references', [])
        info['cve_references'] = extract_cve_references(description, references)

        # Try to get compatible payloads via RPC
        try:
            rpc_payloads = try_get_compatible_payloads_via_rpc(client, exploit_name)
            if rpc_payloads:
                info['compatible_payloads'] = rpc_payloads
            else:
                # Fallback to common payloads for the platform
                platform = info.get('platform', extract_platform_from_name(exploit_name))
                info['compatible_payloads'] = get_common_payloads_for_platform(platform)
        except Exception as e:
            logger.debug(f"RPC payload retrieval failed for {exploit_name}: {e}")
            # Fallback to common payloads for the platform
            platform = info.get('platform', extract_platform_from_name(exploit_name))
            info['compatible_payloads'] = get_common_payloads_for_platform(platform)

        return info

    except Exception as e:
        logger.debug(f"RPC approach failed for {exploit_name}: {e}")
        return None


def get_exploit_detailed_info(exploit_name: str, prefer_rpc: bool = False) -> Optional[Dict[str, Any]]:
    """Get detailed information about a specific exploit using filesystem or RPC approach."""

    # Try RPC approach first if preferred and msgpack is fixed
    if prefer_rpc:
        try:
            rpc_info = get_exploit_detailed_info_via_rpc(exploit_name)
            if rpc_info:
                logger.debug(f"Successfully got exploit info via RPC for {exploit_name}")
                return rpc_info
        except Exception as e:
            logger.debug(f"RPC approach failed for {exploit_name}: {e}")

    # Try to get info from filesystem (most reliable)
    try:
        msf_path = find_metasploit_path()
        if msf_path:
            # Construct file path
            file_path = os.path.join(msf_path, 'modules', 'exploits', f"{exploit_name}.rb")

            if os.path.exists(file_path):
                info = parse_exploit_module_file(file_path, exploit_name)
                if info:
                    # Try to get actual compatible payload modules via RPC
                    try:
                        client = get_thread_local_client()
                        rpc_payloads = try_get_compatible_payloads_via_rpc(client, exploit_name)
                        if rpc_payloads:
                            info['compatible_payloads'] = rpc_payloads
                        else:
                            # Fallback to common payloads for the platform
                            platform = info.get('platform', extract_platform_from_name(exploit_name))
                            info['compatible_payloads'] = get_common_payloads_for_platform(platform)
                    except Exception as e:
                        logger.debug(f"Payload retrieval failed for {exploit_name}: {e}")
                        # Fallback to common payloads for the platform
                        platform = info.get('platform', extract_platform_from_name(exploit_name))
                        info['compatible_payloads'] = get_common_payloads_for_platform(platform)

                    return info
    except Exception as e:
        logger.debug(f"Filesystem approach failed for {exploit_name}: {e}")

    # Try RPC approach as fallback if not preferred initially
    if not prefer_rpc:
        try:
            rpc_info = get_exploit_detailed_info_via_rpc(exploit_name)
            if rpc_info:
                logger.debug(f"Successfully got exploit info via RPC fallback for {exploit_name}")
                return rpc_info
        except Exception as e:
            logger.debug(f"RPC fallback failed for {exploit_name}: {e}")

    # Final fallback: Create basic exploit info
    try:
        info = {
            'name': exploit_name,
            'description': f"Metasploit exploit module: {exploit_name}",
            'rank': 'Unknown',
            'platform': extract_platform_from_name(exploit_name),
            'targets': [],
            'required_options': [],
            'all_options': [],
            'author': 'Unknown',
            'disclosure_date': None,
            'references': [],
            'compatible_payloads': [],
            'cve_references': [],  # Empty for fallback
            'created_at': datetime.now(),
            'updated_at': datetime.now(),
            'data_source': 'basic_fallback'
        }

        return info

    except Exception as e:
        logger.warning(f"Failed to get detailed info for exploit {exploit_name}: {e}")
        return None


def process_single_exploit(exploit_name: str, prefer_rpc: bool = False) -> Optional[Dict[str, Any]]:
    """Worker function to process a single exploit. Thread-safe."""
    try:
        exploit_info = get_exploit_detailed_info(exploit_name, prefer_rpc=prefer_rpc)
        if exploit_info:
            if database.save_exploit_to_database(exploit_info):
                return {"success": True, "exploit_name": exploit_name, "data_source": exploit_info.get("data_source", "unknown")}
            else:
                return {"success": False, "exploit_name": exploit_name, "error": "Database save failed"}
        else:
            return {"success": False, "exploit_name": exploit_name, "error": "Failed to get exploit info"}
    except Exception as e:
        return {"success": False, "exploit_name": exploit_name, "error": str(e)}


def populate_exploits_database(clear_existing: bool = True, batch_size: int = 100, max_workers: int = 8, prefer_rpc: bool = False) -> Dict[str, Any]:
    """
    Populate the exploits database with all available Metasploit exploits using parallel processing.

    Args:
        clear_existing: Whether to clear existing exploits before populating
        batch_size: Number of exploits to process in each batch
        max_workers: Number of parallel threads to use (default: 8)
        prefer_rpc: Whether to prefer RPC over filesystem parsing (default: False)

    Returns:
        Dictionary with population results
    """
    start_time = datetime.now()

    try:
        print("🚀 Starting exploit database population...")

        # Initialize database
        database.init_database()

        # Clear existing exploits if requested
        if clear_existing:
            print("🗑️  Clearing existing exploits database...")
            database.clear_exploits_database()

        # Get Metasploit client for getting the exploit list
        print("🔌 Connecting to Metasploit RPC server...")
        client = get_metasploit_client()

        # Get all available exploits
        print("📋 Retrieving list of all available exploits...")
        all_exploits = client.modules.exploits
        total_exploits = len(all_exploits)

        print(f"📊 Found {total_exploits} total exploits to process")
        print(f"🧵 Using {max_workers} parallel threads for processing")

        # Process exploits in batches using parallel threads
        processed = 0
        successful = 0
        failed = 0

        for i in range(0, total_exploits, batch_size):
            batch_exploits = all_exploits[i:i + batch_size]
            batch_num = (i // batch_size) + 1
            total_batches = (total_exploits + batch_size - 1) // batch_size

            print(f"\n📦 Processing batch {batch_num}/{total_batches} ({len(batch_exploits)} exploits) with {max_workers} threads...")

            # Process batch in parallel
            with ThreadPoolExecutor(max_workers=max_workers) as executor:
                # Submit all tasks for this batch
                future_to_exploit = {
                    executor.submit(process_single_exploit, exploit_name, prefer_rpc): exploit_name
                    for exploit_name in batch_exploits
                }

                # Process completed tasks
                for future in as_completed(future_to_exploit):
                    exploit_name = future_to_exploit[future]
                    try:
                        result = future.result()
                        if result and result.get("success"):
                            successful += 1
                        else:
                            failed += 1
                            if result:
                                logger.debug(f"Failed to process {exploit_name}: {result.get('error', 'Unknown error')}")
                    except Exception as e:
                        logger.error(f"Exception processing exploit {exploit_name}: {e}")
                        failed += 1

                    processed += 1

                    # Progress indicator
                    if processed % 50 == 0:
                        print(f"   ⏳ Processed {processed}/{total_exploits} exploits... (✅ {successful} success, ❌ {failed} failed)")

            print(f"   ✅ Batch {batch_num} completed: {successful - (processed - len(batch_exploits))} successful, {failed - (processed - len(batch_exploits))} failed")

        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds()

        # Get final count from database
        final_count = database.get_exploits_count()

        result = {
            "success": True,
            "total_exploits_found": total_exploits,
            "exploits_processed": processed,
            "exploits_saved": successful,
            "exploits_failed": failed,
            "final_database_count": final_count,
            "duration_seconds": duration,
            "start_time": start_time.isoformat(),
            "end_time": end_time.isoformat(),
            "message": f"Successfully populated exploits database with {successful} exploits"
        }

        print(f"\n✅ Exploit database population completed!")
        print(f"   📊 Total exploits found: {total_exploits}")
        print(f"   ✅ Successfully saved: {successful}")
        print(f"   ❌ Failed: {failed}")
        print(f"   💾 Final database count: {final_count}")
        print(f"   ⏱️  Duration: {duration:.2f} seconds")

        return result

    except Exception as e:
        end_time = datetime.now()
        duration = (end_time - start_time).total_seconds() if 'start_time' in locals() else 0

        error_result = {
            "success": False,
            "error": str(e),
            "duration_seconds": duration,
            "message": f"Failed to populate exploits database: {str(e)}"
        }

        print(f"\n❌ Exploit database population failed: {e}")
        return error_result


def main():
    """Main function for running the exploit population script."""
    import argparse

    parser = argparse.ArgumentParser(description="Populate Metasploit exploits database")
    parser.add_argument("--keep-existing", action="store_true",
                       help="Keep existing exploits (don't clear database first)")
    parser.add_argument("--batch-size", type=int, default=100,
                       help="Number of exploits to process in each batch (default: 100)")
    parser.add_argument("--max-workers", type=int, default=8,
                       help="Number of parallel threads to use (default: 8)")
    parser.add_argument("--prefer-rpc", action="store_true",
                       help="Prefer RPC over filesystem parsing for exploit details")

    args = parser.parse_args()

    # Configure logging
    logging.basicConfig(
        level=logging.INFO,
        format='%(asctime)s - %(name)s - %(levelname)s - %(message)s'
    )

    # Run population
    result = populate_exploits_database(
        clear_existing=not args.keep_existing,
        batch_size=args.batch_size,
        max_workers=args.max_workers,
        prefer_rpc=args.prefer_rpc
    )

    # Print results as JSON for programmatic use
    print("\n" + "="*50)
    print("RESULTS:")
    print(json.dumps(result, indent=2))


if __name__ == "__main__":
    main()
